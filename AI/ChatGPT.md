#### ChatGPT

Generative AI : 오디오, 비디오, 이미지, 텍스트, 코드, 시뮬레이션 등의 새로운 콘텐츠를 생성하는 인공지능 모델
    
- 최근 언어 및 이미지 분석에서 큰 파급력을 보임

ChatGPT : GPT 모델을 기반으로 한 대화형 AI
- Generative : 생성 모델

- Generative AI : 기존 패턴을 기반으로 오디오, 비디오, 이미지, 텍스트, 코드, 시뮬레이션 등의 새로운 콘텐츠를 생성하는 인공지능 모델

- Pre-trained : 사전 훈련. 거대 언어 모델 + 추가 학습 데이터 + 추가 강화 학습.

- Transformer : 트랜스포머 AI 모델. 문장 속의 단어 간 관계를 추적해 맥락과 의미를 학습. 인간처럼 일관되고 연관성이 높은 언어를 구사하여 대화형 작업에 강점.

#### Transformer

트랜스포머 (Transformer) : NNA (Neural Network Architecture) 모델 중 하나. 문장의 맥락을 효과적으로 이해하고 처리함. Attention 메커니즘.

- Self-Attention 메커니즘 : 입력 데이터 간의 관계와 중요도를 계산
- 병렬 처리 가능 : RNN과 달리 순차 처리가 필요 없어 속도가 빠름
- 스케일링 가능 : 대규모 데이터 및 파라미터로 확장 가능
- GPT 모델은 특히 Transformer의 디코더 부분만을 사용

Attention 메커니즘 : AI가 데이터의 맥락과 중요도를 이해하도록 돕는 필수 기술.
입력 데이터의 각 요소가 출력에 얼마나 중요한지 중요도 (Weight)를 계산하는 기법
"중요한 것에 집중한다"는 아이디어를 바탕으로 설계됨.

- Self-Attention : 입력 데이터 내부에서 각 요소 간 중요도를 계산
- Multi-Head Attention : 다양한 관심사(관점)를 병렬로 계산하여 성능 향상

